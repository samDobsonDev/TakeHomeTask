{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyhSZhp-rB6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unitary Interview Stage 2: Clean Code\n",
        "\n",
        "## Background\n",
        "\n",
        "This assessment is designed to evaluate your wider software skills by demonstrating your ability to write code that is:\n",
        "- clean\n",
        "- easily maintained\n",
        "- well-tested\n",
        "- extensible\n",
        "\n",
        "We are more interested in how you approach the design and structure of your implementation rather than evaluating if your code actually works.\n",
        "\n",
        "## Case Study\n",
        "\n",
        "For one of Unitary's products we need to build a pipeline to automatically classify content for 3 different categories and 3 different levels of risks based on a customer's policy. We need to build a backend service that implements the following pipeline:\n",
        "\n",
        "1. Accept an input request (e.g. HTTP) with the content that needs to be moderated. The content can be a video, an image or a text.\n",
        "\n",
        "  - Example request for text:\n",
        "\n",
        "  ```json\n",
        "    {\n",
        "      \"text\": \"Example text\",\n",
        "      \"customer\": \"test\",\n",
        "      \"modality\": \"text\",\n",
        "      \"prediction_type\": \"policy\"\n",
        "    }\n",
        "  ```\n",
        "\n",
        "  - Example request for images or videos:\n",
        "\n",
        "  ```json\n",
        "    {\n",
        "      \"url\": \"Media file url\",\n",
        "      \"customer\": \"test\",\n",
        "      \"modality\": \"image\" # can also be video\n",
        "      \"prediction_type\": \"policy\"\n",
        "    }\n",
        "  ```\n",
        "\n",
        "2. Pre-process the content to convert it into a numerical format to be consumed by our AI models.\n",
        "  - The actual pre-processing is mocked out in the dummy functions at the end of the file. We are more interested in how you will structure your code to process different modalities.\n",
        "\n",
        "3. Send the pre-processed input into different AI models to get detailed categories of harmful content.\n",
        "  - We have given you 3 mock functions in the Appendix section below which you can use. There is one function for each of the 3 different models we use: hate speech, violence, and sexual.\n",
        "  - Example response for hate speech:\n",
        "\n",
        "  ```json\n",
        "    {\n",
        "        \"toxicity\": 0.6,\n",
        "        \"severe_toxicity\": 0.2,\n",
        "        \"obscene\": 0.4,\n",
        "        \"insult\": 0.7,\n",
        "        \"identity_attack\": 0.6,\n",
        "        \"threat\": 0.5\n",
        "    }\n",
        "  ```\n",
        "4. You need to aggregate the detailed responses to end up with three categories, i.e. `hate_speech`, `sexual` and `violence` and a risk level for each category. The values for the risk levels are `low`, `medium` and `high`.\n",
        "\n",
        "The pipeline should combine the model responses and produce a final policy classification output something like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"hate_speech\": \"low\",\n",
        "  \"violence\": \"medium\",\n",
        "  \"sexual\": \"high\"\n",
        "}\n",
        "\n",
        "```\n",
        "The aggregation can be a simple average per model. Take the example of `hate_speech` given above. You can produce an average for all the hate speech categories and determine the risk level with something as simple as:\n",
        "\n",
        "```python\n",
        "  if avg < 0.3:\n",
        "      risk_level = \"low\"\n",
        "  elif avg < 0.6:\n",
        "      risk_level = \"medium\"\n",
        "  else:\n",
        "      risk_level = \"high\"\n",
        "```\n",
        "\n",
        "### Questions\n",
        "\n",
        "1. How would you structure your code in your backend service to a) make it work with different modalities and b) make it easily extensible in order to add new AI models and different categories?\n",
        "\n",
        "  - *Note:* If you don't have time to implement the code for all the different modalities you can select one to write the implementation for as long as your code is easily extensible and reusable.\n",
        "\n",
        "2. How would you test it? Write unit tests to cover different cases for the code you wrote in the previous part.\n",
        "\n",
        "  - *Note:* You don't need to write a fully functional test, only the test definition to explain what functionalities you would test.\n",
        "\n",
        "3. How would you expose this functionality to customers? Write an example API that uses your backend service to produce a policy classification result."
      ],
      "metadata": {
        "id": "zzjZvm5m6w4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Please implement the backend service as described in the Case Study."
      ],
      "metadata": {
        "id": "w2RPmeTwdiFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "02NAIRo6dpzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix\n",
        "### Assumptions & helper functions\n",
        "\n",
        "1. You can download the image from URL specified below and use it as your input into your backend service. For simplicity you can consider videos as a list of frames, so you can provide a list of bytes of the same image."
      ],
      "metadata": {
        "id": "zPZ6fMr162hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "id": "-f4i2DP2610k",
        "outputId": "fd1b2485-e446-4049-9693-96f8aab85cd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "URL = \"https://t3.ftcdn.net/jpg/03/21/62/56/360_F_321625657_rauGwvaYjtbETuwxn9kpBWKDYrVUMdB4.jpg\"\n",
        "IMAGE_PATH = \"./gun.jpg\"\n",
        "\n",
        "resp = requests.get(URL)\n",
        "\n",
        "with open(IMAGE_PATH, \"wb\") as f:\n",
        "    content = resp.content\n",
        "    f.write(resp.content)"
      ],
      "metadata": {
        "id": "00-l0Qea66hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. We have provided some functions to mock the pre-processing and prediction steps of the pipeline which you can use in your code to avoid actually pre-processing the image/video and sending it for classification.\n",
        "\n",
        "```python\n",
        "\n",
        "# Dummy functions\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "def load_image(path: str | Path) -> list[bytes]:\n",
        "  with open(path, \"rb\") as f:\n",
        "    image_bytes = f.read()\n",
        "  return [image_bytes]\n",
        "\n",
        "def load_video(path: str | Path) -> list[bytes]:\n",
        "  img_bytes = load_image(path)\n",
        "  return img_bytes * 10\n",
        "\n",
        "def preprocess_text(input_data: str) -> list[int]:\n",
        "  return [random.randint(1, 100)] * 16\n",
        "\n",
        "def preprocess_image(input_data: list[bytes]) -> list[int]:\n",
        "  return [random.randint(1,100)] * 16\n",
        "\n",
        "def preprocess_video(input_data: list[bytes]) -> llist[list[int]]:\n",
        "  return [[random.randint(1,100)] * 16] * len(input_data)\n",
        "\n",
        "async def predict_hate_speech(input_data: list[int]) -> dict[str, float]:\n",
        "    return {\n",
        "        \"toxicity\": random.random(),\n",
        "        \"severe_toxicity\": random.random(),\n",
        "        \"obscene\": random.random(),\n",
        "        \"insult\": random.random(),\n",
        "        \"identity_attack\": random.random(),\n",
        "        \"threat\": random.random()\n",
        "    }\n",
        "\n",
        "async def predict_sexual(input_data: list[int]) -> dict[str, float]:\n",
        "  return {\n",
        "      \"sexual_explicit\": random.random(),\n",
        "      \"adult_content\": random.random(),\n",
        "      \"adult_toys\": random.random()\n",
        "  }\n",
        "\n",
        "\n",
        "async def predict_violence(input_data: list[int]) -> dict[str, float]:\n",
        "  return {\n",
        "      \"violence\": random.random(),\n",
        "      \"firearm\": random.random(),\n",
        "      \"knife\": random.random()\n",
        "  }\n",
        "```"
      ],
      "metadata": {
        "id": "wJxRdeDZ7QCj"
      }
    }
  ]
}